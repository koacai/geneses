optimizer:
  _target_: torch.optim.AdamW
  lr: 1e-4

hubert:
  model_name: ${data.datamodule.hubert_model_name}
  layer: 6

train_hubert: true

flow_predictor:
  in_channels: 1536 # 768*2
  out_channels: 768
  channels: [256, 256]
  dropout: 0.05
  attention_head_dim: 64
  n_blocks: 1
  num_mid_blocks: 2
  num_heads: 2
  act_fn: snakebeta
